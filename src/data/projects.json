[
    {
        "id": 1,
        "thumbnail": "../../res/projects/ecodash-thumb.png",
        "images": [
            "../../res/projects/ecodash-1.jpg",
            "../../res/projects/ecodash-2.jpg"
        ],
        "projectTitle": "Eco-Dash",
        "projectInfo": [
            [
                "Overview",
                "Ecodash was a hackathon project for 'EARTH HACK'. It was the winner of Toyota Connected's 'Driver Interface' prize category. The application takes in real data -simulated in real time- and translates that data into a driver score. The score is determined by looking at the driver's vehicle speed, steering angle, and engine speed (RPM), and calculates a driving score based on how the driver is operating their vehicle."
            ],
            [
                "Inspiration",
                "We at Eco-Dash wanted to create an application that can run on the heads up display that would allow drivers to view their own driving habits and compare themselves against their community."
            ],
            [
                "What it does",
                "Eco-Dash reads in telemetry data from the cars numerous sensors, such as vehicle speed, steering angle, and engine speed (RPM), and calculates a driving score based on how the driver is operating their vehicle. The driver can also see their score based against their local community, friends, or many other options"
            ],
            [
                "How we built it",
                "The application is a fully functioning full stack web application (capable of being ported to an in car infotainment console). The front end UI is built primarily with React.js and React-RT-Chart.js for visualizations. This application will then talk to an express server running on a Node.js instance sitting inside of an AWS - EC2 Compute node."
            ]
        ],
        "tags": [
            "Software",
            "Hackathon",
            "Web",
            "MongoDB"
        ],
        "links": {
            "github": "https://github.com/kolten/toyota-eco-dash",
            "devpost": "https://devpost.com/software/eco-drivr"
        },
        "date": "Sun Apr 23 2017 00:00:00 GMT-0500 (Central Daylight Time)"
    },
    {
        "id": 2,
        "thumbnail": "../../res/projects/remix-me-thumb.png",
        "images": [
            "../../res/projects/remix-me-0.jpg",
            "../../res/projects/remix-me-1.jpg",
            "../../res/projects/remix-me-2.jpg",
            "../../res/projects/remix-me-3.jpg"
        ],
        "projectTitle": "Remix.Me",
        "projectInfo": [
            [
                "Overview",
                "Remix.Me was a hackthon project for SXSW's 2017 Music Hackathon. The project was designed for the implementation of Socan's API - A performing rights organization. The project helps remix artists compete in remix copetitions by placing them in a head to head competition with other remixer's of the same track."
            ],
            [
                "Inspiration",
                "It can be difficult for upcoming artists to be noticed. Even those with a lot of talent and skill can be easily overlooked in the sea of voices wanting to be heard. We help those with the passion to create high-quality music stand out in the crowd."
            ],
            [
                "What It Does",
                "Remix.Me provides a platform in which musicians can browse through a category of remix contests. Once they've chosen one, they can enter the competition and compete. In order to complete their submission, though, they must work with us to help determine which remixes are the highest quality. This is done in a blind tournament style, in which community members vote for which contest they believe is best."
            ]
        ],
        "tags": [
            "Web",
            "MongoDB",
            "Software",
            "Hackathon"
        ],
        "links": {
            "github": "https://github.com/SXSWMusikathon/MusikathonApp",
            "devpost": "https://devpost.com/software/remix-me"
        },
        "date": "Wed Mar 15 2017 00:00:00 GMT-0500 (Central Daylight Time)"
    },
    {
        "id": 3,
        "thumbnail": "../../res/projects/jibo-fam-thumb.jpeg",
        "images": [
            "../../res/projects/jibo-fam-0.png",
            "../../res/projects/jibo-fam-1.gif"
        ],
        "projectTitle": "Jibo Fam",
        "projectInfo": [
            [
                "Overview",
                "Jibo is a friendly social little robot. This project was done for MLH Prime - a hackathon project completed in less than 24 hours. Rock paper jibo's goal was to teach jibo to play the game rock paper scissors. The two main sections of completing the project involved computer vision and learning Jibo's sdk. Jibo is currently in pre-release state, and the SDK is currently under development. Tools were given to us, allowing us to create jibo 'animations' and responses to things said to it through the use of it's 'grammar' functionality. Once we developed the framework for the application we went to work on developing a computer vision call that we made, to determine if which gesture was picked for the game. This call was made to a custom online database, where we compared the image jibo takes with his camera to our training images."
            ],
            [
                "What it does",
                "Jibo plays rock paper scissors!Using Jibo's built in technology we are able to communicate with it and let it communicate with us. Playing rock paper scissors without the physical part of the game just doesn't feel the same though. We used the camera on the front of the robot to snap a picture! We feed this picture through out server and run computer vision algorithms to determine what was played, and who wins!"
            ],
            [
                "Development",
                "This is our first project working with Jibo's sdk. We had to learn a lot from scratch, and ran into a few roadblocks. Luckily we were able to find solutions to all of our problems, and were able to fully complete our intended project.The computer vision technology was especially tricky. It is easy to tell that there is a hand in the picture - but not what gesture it is making. Luckily we were able to find a image processing technique that worked and does a fairly good job of determining what gesture is made."
            ]
        ],
        "tags": [
            "Software",
            "Hackathon"
        ],
        "links": {
            "github": "https://github.com/RobertAron/Rock-Paper-Jibo/",
            "devpost": "https://devpost.com/software/jibo-fam"
        },
        "date": "Wed Nov 15 2016 00:00:00 GMT-0600 (Central Standard Time)"
    },
    {
        "id": 4,
        "thumbnail": "../../res/projects/who-we-are-thumb.png",
        "images": [
            "../../res/projects/who-we-are-1.jpg",
            "../../res/projects/who-we-are-2.jpg"
        ],
        "projectTitle": "Who We Are",
        "projectInfo": [
            [
                "Overview",
                "'Who We Are' is a short video to promote the Dallas film crew. The project was showcased at the Dallas film crew's 2017 premier and is currently used recruitment for the organization. My contribution to the film was the narration recording and film score."
            ],
            [
                "Production",
                "I was contacted by the Dallas Film Crew to help with the production on their trailer/recruitment video. When I joined production the film was in picture lock and needed narration and music. We brought Elissa Annette into my home studio and recorded the narration. The score was inspired with the idea of starting something small and growing into a huge production. The score accomplishes this by starting with a simple piano melody but growing into a full orchestral texture."
            ]
        ],
        "tags": [
            "Audio",
            "Music"
        ],
        "links": {
            "youtube": "ZvWOEwXFpOU"
        },
        "date": "Wed Jul 17 2017 00:00:00 GMT-0600 (Central Standard Time)"
    },
    {
        "id": 5,
        "thumbnail": "../../res/projects/Response-Variable-thumb.jpg",
        "images": [
            "../../res/projects/Response-Variable-02.jpg",
            "../../res/projects/Response-Variable-01.jpg"
        ],
        "projectTitle": "Response Variable",
        "projectInfo": [
            [
                "Overview",
                "'Response Variable' is a short electro track used to showcase FL Studio's then newly implemented live performance mode. The track won Image Line's live performance contest."
            ],
            [
                "Production",
                "The track was developed using FL Studio's beta version of live performance mode. The main motivation behind the track was to make a song that was interesting to listen to, and also interesting to watch be performed. Short audio cips were used that could be repeated in multiple areas throughout the track. Overall the track grew into multiple sample pages in order to transition fully through different sections of the song. A piano interlude in the break of the track, as well as added to the final drop in order to finish the track in a way that feel meaningful and not too repetitive."
            ]
        ],
        "tags": [
            "Audio",
            "Music"
        ],
        "links": {
            "youtube": "CJEPYRIMlDg"
        },
        "date": "Fri Dec 21 2012 00:00:00 GMT-0600 (Central Standard Time)"
    },
    {
        "id": 6,
        "thumbnail": "../../res/projects/uta-now-thumb.png",
        "images": [
            "../../res/projects/uta-now-1.png",
            "../../res/projects/uta-now-2.png"
        ],
        "projectTitle": "UTA Now",
        "projectInfo": [
            [
                "Overview",
                "UTA Now is a phone application that allows students to find out what is going on around UTA. As an organizer, the app allows you to share upcoming events and information about when and where they'll take place. As a user the app allows you to see events that will happen soon around UTA and get information about what those events are about."
            ],
            [
                "Inspiration",
                "UTA has a wide range of clubs and events that happen on and around campus. Due to the overwhelming number clubs it can sometimes be hard to track down where and when events are happening. UTA Now allows you to see events that are coming up in the near future in an organized way thats simple to navigate. You can sign up through Facebook in order to place comments on events, or just browse the catalog without an account."
            ],
            [
                "Development",
                "UTA Now was developed using the agile methodology. Two teams were formed to work on the native Android development and native IOS development. The backend was developed using firebase, a startup database developed by Google. Facebook login was implemented to allow ease of use. Logging in allows the user to comment on upcoming events and favorite events. This information is stored on the server's and transferred between devices."
            ]
        ],
        "tags": [
            "Software"
        ],
        "links": {
            "github": "https://github.com/RobertAron/UTANow-Android"
        },
        "date": "Tue Apr 05 2016 00:00:00 GMT-0600 (Central Standard Time)"
    },
    {
        "id": 7,
        "thumbnail": "../../res/projects/smartAlarm-thumb.jpg",
        "images": [
            "../../res/projects/smartAlarm-1.jpg"
        ],
        "projectTitle": "Smart Alarm",
        "projectInfo": [
            [
                "Overview",
                "SmartAlarm takes in multiple real world data points, such as weather, traffic, user sleep cycles, and user travel history, to determine an optimal time to set an alarm. The user simply enters a destination and a time they'd like to arrive, and our app takes care of the rest."
            ],
            [
                "How Does It Work",
                "Our app is a native Android application. We use several Google Play services such as Google-Places and the Google-Distance-Matrix, we also use forecast.io for real time weather data."
            ]
        ],
        "tags": [
            "Software",
            "Hackathon"
        ],
        "links": {
            "github": "https://github.com/Kevin-Chung/Smart-Alarm-Android-App"
        },
        "date": "Fri Sep 09 2016 00:00:00 GMT-0600 (Central Standard Time)"
    },
    {
        "id": 8,
        "thumbnail": "../../res/projects/shooting-star-thumb.jpg",
        "images": [
            "../../res/projects/shooting-star-1.jpg"
        ],
        "projectTitle": "Shooting Star",
        "projectInfo": [
            [
                "Overview",
                "Shooting Star is a future bass electronic track. The track features an uplifting meleody accompanied by cute percussion elements."
            ],
            [
                "Future Bass Elements",
                "Future bass is a genre that has fairly defined standards. Chords elements are usually whips - elements with fairly long attack times, that effect an opening filter. Short, punchy and clear drums are almost universally used. These punchy elements cut even more through the track due to heavy use of side chaining. Vocal chops are also frequently used to fill out the track rhythmically. Finally, leads melodies usually have simple structures but are catchy in nature."
            ]
        ],
        "tags": [
            "Music"
        ],
        "links": {
            "youtube": "PVmCiVLR7dY"
        },
        "date": "Sun Sep 10 2017 00:00:00 GMT-0600 (Central Standard Time)"
    }
]